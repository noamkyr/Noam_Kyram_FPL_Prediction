{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOH1xwwTV4F5",
        "outputId": "a377baf1-96d5-45fa-a42e-cdc01126537f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "Successfully installed scikit-learn-1.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaDuL861WC9Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78a8df68-5dc1-4124-d38f-479473c41c5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/experimental/enable_hist_gradient_boosting.py:15: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "import json\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PowerTransformer\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import make_scorer\n",
        "import concurrent.futures\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "get the data frames calling the api"
      ],
      "metadata": {
        "id": "fEUXuEeEoQi6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msf5ATziWL-o"
      },
      "outputs": [],
      "source": [
        "def get_data():\n",
        "    url_players = \"https://fantasy.premierleague.com/api/bootstrap-static/\"\n",
        "\n",
        "    response = requests.get(url_players)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        fixtures_data = response.json()\n",
        "        # do something with the fixtures data here\n",
        "    else:\n",
        "        print(f\"Failed to retrieve fixtures data: {response.status_code}\")\n",
        "        exit()\n",
        "    return fixtures_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "create the players and teams dataframe from the response"
      ],
      "metadata": {
        "id": "CgQ9TsaOpLz8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWpq78xchV45"
      },
      "outputs": [],
      "source": [
        "def get_players_data(fixtures_data):\n",
        "    df_players = pd.DataFrame(fixtures_data['elements'])\n",
        "    return df_players"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMVzoFHwhgA4"
      },
      "outputs": [],
      "source": [
        "def get_teams_data(fixtures_data):\n",
        "    df_teams = pd.DataFrame(fixtures_data['teams'])\n",
        "    return df_teams"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "create a merged df, each player will have its team data"
      ],
      "metadata": {
        "id": "Ul_jKO-apUPz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T83xC-1_iZ2B"
      },
      "outputs": [],
      "source": [
        "def merge_players_teams(df_players, df_teams):\n",
        "\n",
        "    merged_df = pd.merge(df_players, df_teams, left_on='team',right_on='id', suffixes=('_player', '_team'), how='inner')\n",
        "\n",
        "    merged_df1 = merged_df[merged_df['chance_of_playing_next_round'] >50.0]\n",
        "    merged_df2 = merged_df[pd.isna(merged_df['chance_of_playing_next_round'])]\n",
        "\n",
        "    merged_df = pd.concat([merged_df1, merged_df2], ignore_index=True)\n",
        "\n",
        "    merged_df = merged_df[['id_player','element_type','team','web_name']]\n",
        "\n",
        "    return merged_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "create the fixtures data frame calling the api"
      ],
      "metadata": {
        "id": "UJuDelwBpdvL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fp6agsYGi-aZ"
      },
      "outputs": [],
      "source": [
        "def get_gw_data(dt):\n",
        "\n",
        "    df = pd.DataFrame(dt['events'])\n",
        "    df_teams = pd.DataFrame(dt['teams'])\n",
        "    next_updated_gw = df[df['is_next'] == True]\n",
        "    num_updated_next_gw = next_updated_gw.index[0] + 1\n",
        "\n",
        "\n",
        "    url_events = \"https://fantasy.premierleague.com/api/fixtures/?event=\"+str(num_updated_next_gw)\n",
        "    #print(url_events)\n",
        "    #print(num_updated_next_gw)\n",
        "\n",
        "    response = requests.get(url_events)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        fixtures_data = response.json()\n",
        "        # do something with the fixtures data here\n",
        "    else:\n",
        "        print(f\"Failed to retrieve fixtures data: {response.status_code}\")\n",
        "        exit()\n",
        "\n",
        "    df_fix = pd.DataFrame(fixtures_data)\n",
        "    return df_fix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "create the players history in the current season, using the api"
      ],
      "metadata": {
        "id": "VxspTCqYpkAl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRKVJJxaNiPE"
      },
      "outputs": [],
      "source": [
        "def get_players_hist(merged_df):\n",
        "\n",
        "    id_game = list()\n",
        "    id_player = list()\n",
        "    id_rival = list()\n",
        "    team = list()\n",
        "    was_home = list()\n",
        "    fpl_total_points = list()\n",
        "    player_pos = list()\n",
        "    minu = list()\n",
        "\n",
        "    for i in merged_df['id_player']:\n",
        "        player_hist_url = \"https://fantasy.premierleague.com/api/element-summary/\"+str(i)+\"/\"\n",
        "        response = requests.get(player_hist_url)\n",
        "\n",
        "        # Check if the request was successful (HTTP status code 200 means success)\n",
        "        if response.status_code == 200:\n",
        "            # Extract the player's history from the JSON response\n",
        "            history = response.json()\n",
        "\n",
        "        else:\n",
        "            # If the request was not successful, print the error message\n",
        "            print(f\"Error: {response.text}\")\n",
        "            exit()\n",
        "\n",
        "        df_player_hist = pd.DataFrame(history['history'])\n",
        "\n",
        "\n",
        "        if not df_player_hist.columns.tolist():\n",
        "            continue\n",
        "\n",
        "        df_player_hist = df_player_hist.drop(['kickoff_time', 'value', 'transfers_balance', 'selected'  ,'transfers_in', 'transfers_out'],axis= 1)\n",
        "\n",
        "\n",
        "        team_id = merged_df.loc[merged_df['id_player'] == i]['team']\n",
        "        team_id = int(team_id.iloc[0])\n",
        "\n",
        "        player_type = merged_df.loc[merged_df['id_player'] == i]['element_type'].iloc[0]\n",
        "        l = len(df_player_hist)\n",
        "        for j in range(l):\n",
        "            #x = df_player_hist.iloc[j]['fixture']\n",
        "            #id_game.append(x)\n",
        "            id_player.append(df_player_hist.iloc[j]['element'])\n",
        "            id_rival.append(df_player_hist.iloc[j]['opponent_team'])\n",
        "            team.append(team_id)\n",
        "            was_home.append(df_player_hist.iloc[j]['was_home'])\n",
        "            fpl_total_points.append(df_player_hist.iloc[j]['total_points'])\n",
        "            player_pos.append(player_type)\n",
        "            minu.append(df_player_hist.iloc[j]['minutes'])\n",
        "\n",
        "\n",
        "    players_games = pd.DataFrame({'id_player':id_player, 'id_rival': id_rival, 'player_team_id':team,\n",
        "                                  'was_home':was_home, 'minutes': minu , 'fpl_total_points': fpl_total_points, 'player_pos':player_pos})\n",
        "\n",
        "    return players_games.sort_values('fpl_total_points', ascending= False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6816A-2MQcev"
      },
      "source": [
        "alternative to get hist:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_players_hist2(merged_df):\n",
        "    player_ids = merged_df['id_player'].tolist()\n",
        "    player_hist_urls = [f\"https://fantasy.premierleague.com/api/element-summary/{i}/\" for i in player_ids]\n",
        "\n",
        "    player_data = []\n",
        "    for url, player_id in zip(player_hist_urls, player_ids):\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            history = response.json()\n",
        "            if 'history' in history:\n",
        "                player_data.extend(history['history'])\n",
        "\n",
        "    if not player_data:\n",
        "        print(\"No player history data found.\")\n",
        "        return None\n",
        "\n",
        "    df_player_hist = pd.DataFrame(player_data)\n",
        "    if df_player_hist.empty:\n",
        "        print(\"Player history DataFrame is empty.\")\n",
        "        return None\n",
        "\n",
        "    # Assuming df_teams contains team information\n",
        "\n",
        "    # Merge with team strength data\n",
        "    df_player_hist = pd.merge(df_player_hist, df_teams[['id', 'strength']], left_on='opponent_team', right_on='id')\n",
        "\n",
        "    # Drop unnecessary columns\n",
        "    df_player_hist = df_player_hist.drop(['kickoff_time', 'value', 'transfers_balance', 'selected', 'transfers_in', 'transfers_out'], axis=1)\n",
        "\n",
        "    player_game_data = []\n",
        "\n",
        "    for _, row in merged_df.iterrows():\n",
        "        player_id = row['id_player']\n",
        "        team_id = row['team']\n",
        "        player_type = row['element_type']\n",
        "        team_str = df_teams[df_teams['id'] == team_id]['strength'].iloc[0]\n",
        "\n",
        "        player_hist_subset = df_player_hist[df_player_hist['element'] == player_id]\n",
        "\n",
        "        if not player_hist_subset.empty:\n",
        "            for _, game_row in player_hist_subset.iterrows():\n",
        "                player_game_data.append({\n",
        "                    'id_player': player_id,\n",
        "                    'id_rival': game_row['opponent_team'],\n",
        "                    'player_team_id': team_id,\n",
        "                    'was_home': game_row['was_home'],\n",
        "                    'minutes': game_row['minutes'],\n",
        "                    'fpl_total_points': game_row['total_points'],\n",
        "                    'player_pos': player_type\n",
        "                })\n",
        "\n",
        "    players_games = pd.DataFrame(player_game_data)\n",
        "\n",
        "    return players_games.sort_values('fpl_total_points', ascending=False)"
      ],
      "metadata": {
        "id": "gR0U_VkIQK22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "create a data frame with the data about the upcoming fixture, with column to predict"
      ],
      "metadata": {
        "id": "K5KZxW74pyXE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOKFqAOpOJVP"
      },
      "outputs": [],
      "source": [
        "def get_results_to_predict(df_fix, merged_df):\n",
        "    #id_game = list() #\n",
        "    id_player = list() #\n",
        "    id_rival = list() #\n",
        "    team = list() # i\n",
        "    is_home = list() #\n",
        "    fpl_total_points = list() # to predict\n",
        "    player_pos = list() #\n",
        "    minu = list() #\n",
        "    print(\"@@@@@\")\n",
        "    print(df_gw.head(10))\n",
        "    print(type(df_gw['team_a']))\n",
        "    player_team_id = list()\n",
        "    for i in df_gw['team_a']:\n",
        "        x = 2\n",
        "        print(\"i is \"+ str(i))\n",
        "        id_rival_x = df_gw.loc[df_gw['team_a'] == i]['team_h'].iloc[0]\n",
        "        #print(\"team is \" + str(i) + \" rival is \" + str(id_rival_x))\n",
        "        #print(\"hello\")\n",
        "\n",
        "        temp_df = df_merged.loc[df_merged['team'] == i]\n",
        "        temp_ser = temp_df['id_player']\n",
        "        temp_lst = temp_ser.to_list()\n",
        "        id_player.extend(temp_lst)\n",
        "        lenp = len(temp_lst)\n",
        "        #print(lenp)\n",
        "\n",
        "        temp_lst2 = np.empty(lenp)\n",
        "        temp_lst2[:] = id_rival_x\n",
        "        id_rival.extend(temp_lst2)\n",
        "\n",
        "        print(len(id_rival))\n",
        "\n",
        "        temp_lst2 = np.empty(lenp)\n",
        "        temp_lst2[:] = False\n",
        "        is_home.extend(temp_lst2)\n",
        "\n",
        "        id_game_x = df_gw.loc[df_gw['team_a'] == i]['id'].iloc[0]\n",
        "        temp_lst2 = np.empty(lenp)\n",
        "        temp_lst2[:] = id_game_x\n",
        "        #id_game.extend(temp_lst2)\n",
        "\n",
        "\n",
        "        team_strength_x = df_gw.loc[df_gw['team_a'] == i]['team_a_difficulty'].iloc[0]\n",
        "        temp_lst2 = np.empty(lenp)\n",
        "        temp_lst2[:] = team_strength_x\n",
        "        #team_strength.extend(temp_lst2)\n",
        "        print(\"team is \" + str(i) + \" strength is \" + str(team_strength_x))\n",
        "\n",
        "        rival_strength_x = df_gw.loc[df_gw['team_a'] == i]['team_h_difficulty'].iloc[0]\n",
        "        temp_lst2 = np.empty(lenp)\n",
        "        temp_lst2[:] = rival_strength_x\n",
        "        #rival_strength.extend(temp_lst2)\n",
        "\n",
        "        temp_lst2 = np.empty(lenp)\n",
        "        temp_lst2[:] = i\n",
        "        player_team_id.extend(temp_lst2)\n",
        "\n",
        "\n",
        "        for j in temp_ser.tolist():\n",
        "            posi_x = df_merged.loc[df_merged['id_player'] == j]['element_type'].iloc[0]\n",
        "            player_pos.append(posi_x)\n",
        "\n",
        "\n",
        "\n",
        "    for i in df_gw['team_h']:\n",
        "        x = 2\n",
        "\n",
        "        id_rival_x = df_gw.loc[df_gw['team_h'] == i]['team_a'].iloc[0]\n",
        "\n",
        "\n",
        "        temp_df = df_merged.loc[df_merged['team'] == i]\n",
        "        temp_ser = temp_df['id_player']\n",
        "        temp_lst = temp_ser.to_list()\n",
        "        id_player.extend(temp_lst)\n",
        "        lenp = len(temp_lst)\n",
        "        #print(lenp)\n",
        "\n",
        "\n",
        "        temp_lst2 = np.empty(lenp)\n",
        "        temp_lst2[:] = id_rival_x\n",
        "        id_rival.extend(temp_lst2)\n",
        "\n",
        "        #print(len(id_rival))\n",
        "\n",
        "        temp_lst2 = np.empty(lenp)\n",
        "        temp_lst2[:] = True\n",
        "        is_home.extend(temp_lst2)\n",
        "\n",
        "        id_game_x = df_gw.loc[df_gw['team_h'] == i]['id'].iloc[0]\n",
        "        temp_lst2 = np.empty(lenp)\n",
        "        temp_lst2[:] = id_game_x\n",
        "        #id_game.extend(temp_lst2)\n",
        "\n",
        "\n",
        "        team_strength_x = df_gw.loc[df_gw['team_h'] == i]['team_h_difficulty'].iloc[0]\n",
        "        temp_lst2 = np.empty(lenp)\n",
        "        temp_lst2[:] = team_strength_x\n",
        "        #team_strength.extend(temp_lst2)\n",
        "\n",
        "        rival_strength_x = df_gw.loc[df_gw['team_h'] == i]['team_a_difficulty'].iloc[0]\n",
        "        temp_lst2 = np.empty(lenp)\n",
        "        temp_lst2[:] = rival_strength_x\n",
        "        #rival_strength.extend(temp_lst2)\n",
        "\n",
        "        temp_lst2 = np.empty(lenp)\n",
        "        temp_lst2[:] = i\n",
        "        player_team_id.extend(temp_lst2)\n",
        "\n",
        "\n",
        "        for j in temp_ser.tolist():\n",
        "\n",
        "            posi_x = df_merged.loc[df_merged['id_player'] == j]['element_type'].iloc[0]\n",
        "            player_pos.append(posi_x)\n",
        "\n",
        "\n",
        "    minu = np.empty(len(id_player))\n",
        "    minu[:] = 90\n",
        "\n",
        "\n",
        "    fpl_total_points = np.empty(len(id_player))\n",
        "    fpl_total_points[:] = np.nan\n",
        "\n",
        "\n",
        "    print(len(id_player))\n",
        "    print(len(id_rival))\n",
        "    print(len(player_team_id))\n",
        "    print(len(is_home))\n",
        "    print(len(minu))\n",
        "    print(len(fpl_total_points))\n",
        "    print(len(fpl_total_points))\n",
        "    print(len(player_pos))\n",
        "\n",
        "    dicti = pd.DataFrame({'id_player':id_player, 'id_rival': id_rival, 'player_team_id':player_team_id,\n",
        "                                  'is_home':is_home, 'minutes': minu , 'fpl_total_points': fpl_total_points, 'player_pos':player_pos})\n",
        "    #for i in dicti.values():\n",
        "    #  print(len(i))\n",
        "\n",
        "    print(\"%%%%%\")\n",
        "\n",
        "    players_upcoming_games = pd.DataFrame(dicti)\n",
        "    print(players_upcoming_games.head())\n",
        "    return players_upcoming_games"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_vMB7GLOEYX"
      },
      "source": [
        "main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "P6MuJVZFOlvz",
        "outputId": "7924071c-5f2e-4ba1-e11d-ddb9911bf4c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "385    351\n",
            "Name: id, dtype: int64\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'get_teams_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-40fa623f8a74>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_players\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_players\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'web_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Haaland'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdf_teams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_teams_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mdf_merged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_players_teams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_players\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_teams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_merged\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_merged\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id_player'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m709\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'web_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_teams_data' is not defined"
          ]
        }
      ],
      "source": [
        "dt = get_data()\n",
        "df_gw = get_gw_data(dt)\n",
        "df_players = get_players_data(dt)\n",
        "\n",
        "\n",
        "print(df_players[df_players['web_name'] == 'Haaland']['id'].head())\n",
        "df_teams = get_teams_data(dt)\n",
        "df_merged = merge_players_teams(df_players,df_teams)\n",
        "print(df_merged[df_merged['id_player'] == 709]['web_name'].head())\n",
        "\n",
        "\n",
        "#print(df_merged.columns.tolist())\n",
        "\n",
        "df_merged = merge_players_teams(df_players, df_teams)\n",
        "\n",
        "df_hist = get_players_hist2(df_merged)\n",
        "#df_hist = get_h2(df_merged)\n",
        "#print(df_hist.sort_values(by='fpl_total_points', ascending=False))\n",
        "df_guess = get_results_to_predict(df_gw, df_merged)\n",
        "\n",
        "print(df_guess.head())\n",
        "\n",
        "df_guess.rename(columns={'is_home': 'was_home'}, inplace=True)\n",
        "df_guess = df_guess[df_hist.columns.to_list()]\n",
        "print(df_guess.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JStsddzuY8U",
        "outputId": "86a91f7d-d337-447f-9fbd-b7403e73445e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      id_player  id_rival  player_team_id  was_home  minutes  \\\n",
            "7699        355        20              13      True       82   \n",
            "7678        355        10              13      True       90   \n",
            "7688        355         7              13     False       90   \n",
            "7680        355        14              13     False       90   \n",
            "7694        355         6              13     False       79   \n",
            "\n",
            "      fpl_total_points  player_pos  \n",
            "7699                21           4  \n",
            "7678                20           4  \n",
            "7688                16           4  \n",
            "7680                16           4  \n",
            "7694                13           4  \n"
          ]
        }
      ],
      "source": [
        "#print(df_hist.head())\n",
        "#print(df_merged[df_merged['id_player'] == 26].head())\n",
        "#print(df_hist.head())\n",
        "print(df_hist[df_hist['id_player'] == 355].head())\n",
        "#print(df_guess[df_guess['player_team_id'] == 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JP_5OXyLKiQ3"
      },
      "source": [
        "guessing the ucoming fpl score of every player"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQJY_icX0Yo_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fa61eff-b3e2-47c7-f3f0-654ad835c15a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['id_player', 'id_rival', 'player_team_id', 'was_home', 'player_pos']\n",
            "Mean Squared Error: 6.565445998093295\n",
            "['id_player', 'id_rival', 'player_team_id', 'was_home', 'player_pos']\n",
            "     id_player  id_rival  player_team_id  is_home  minutes  fpl_total_points  \\\n",
            "277         29       9.0             1.0      1.0     90.0             11.39   \n",
            "276         26       9.0             1.0      1.0     90.0              9.28   \n",
            "268         12       9.0             1.0      1.0     90.0              8.30   \n",
            "264          5       9.0             1.0      1.0     90.0              8.22   \n",
            "448        308      20.0            11.0      1.0     90.0              7.98   \n",
            "..         ...       ...             ...      ...      ...               ...   \n",
            "519        471      18.0            17.0      1.0     90.0             -0.15   \n",
            "159        548      11.0            20.0      0.0     90.0             -0.16   \n",
            "523        483      18.0            17.0      1.0     90.0             -0.17   \n",
            "7          257       1.0             9.0      0.0     90.0             -0.50   \n",
            "521        477      18.0            17.0      1.0     90.0             -0.84   \n",
            "\n",
            "     player_pos  \n",
            "277           2  \n",
            "276           3  \n",
            "268           3  \n",
            "264           2  \n",
            "448           3  \n",
            "..          ...  \n",
            "519           2  \n",
            "159           2  \n",
            "523           4  \n",
            "7             2  \n",
            "521           4  \n",
            "\n",
            "[546 rows x 7 columns]\n"
          ]
        }
      ],
      "source": [
        "guess_tmp = df_guess.copy()\n",
        "hist_tmp = df_hist.copy()\n",
        "hist_tmp = hist_tmp.drop('minutes', axis=1)\n",
        "guess_tmp = guess_tmp.drop('minutes', axis=1)\n",
        "\n",
        "# Encode categorical features using Label Encoding\n",
        "label_encoders = {}\n",
        "categorical_cols = df_hist.columns.to_list()\n",
        "categorical_cols.remove('fpl_total_points')\n",
        "categorical_cols.remove('minutes')\n",
        "print(categorical_cols)\n",
        "\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    hist_tmp[col] = le.fit_transform(hist_tmp[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Split the dataset into features (X) and target (Y)\n",
        "X = hist_tmp.drop('fpl_total_points', axis=1)\n",
        "Y = hist_tmp['fpl_total_points']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build and train a Random Forest Regressor model\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "mse = mean_squared_error(Y_test, Y_pred)\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "\n",
        "categorical_cols = df_guess.columns.to_list()\n",
        "categorical_cols.remove('fpl_total_points')\n",
        "categorical_cols.remove('minutes')\n",
        "print(categorical_cols)\n",
        "\n",
        "\n",
        "# Encode categorical features in the new dataset using new Label Encoders\n",
        "new_label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    guess_tmp[col] = le.fit_transform(guess_tmp[col])\n",
        "    new_label_encoders[col] = le\n",
        "\n",
        "# Use the trained model to make predictions on the new dataset\n",
        "new_predictions = model.predict(guess_tmp.drop('fpl_total_points', axis=1))\n",
        "\n",
        "# Add the predictions as a new column 'Predicted_Income' in the new dataset\n",
        "df_guess['fpl_total_points'] = new_predictions\n",
        "\n",
        "# Display the new dataset with predictions\n",
        "\n",
        "#print(\"dfguess after predicting\")\n",
        "#print(df_guess[df_guess['player_team_id'] == 2])\n",
        "df_guess.rename(columns={'was_home': 'is_home'}, inplace=True)\n",
        "sorted_df = df_guess.sort_values(by='fpl_total_points', ascending=False)\n",
        "print(sorted_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "runnings samples and outputs.\n"
      ],
      "metadata": {
        "id": "60krRKLVqgfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_df = pd.merge(sorted_df, df_merged[['id_player', 'web_name']], on='id_player', how='inner')\n",
        "print(sorted_df.head(10))\n",
        "\n",
        "\n",
        "print(sorted_df[sorted_df['player_pos'] == 1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pQpjjcI1Sxf",
        "outputId": "4a9b6654-4f0b-45d2-d3e7-ef260c464175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id_player  id_rival  player_team_id  is_home  minutes  fpl_total_points  \\\n",
            "0         29       9.0             1.0      1.0     90.0             11.39   \n",
            "1         26       9.0             1.0      1.0     90.0              9.28   \n",
            "2         12       9.0             1.0      1.0     90.0              8.30   \n",
            "3          5       9.0             1.0      1.0     90.0              8.22   \n",
            "4        308      20.0            11.0      1.0     90.0              7.98   \n",
            "5        775      18.0            17.0      1.0     90.0              7.97   \n",
            "6         77       7.0             3.0      0.0     90.0              7.79   \n",
            "7        353      19.0            13.0      1.0     90.0              7.28   \n",
            "8        172      16.0             6.0      1.0     90.0              7.10   \n",
            "9        526      13.0            19.0      0.0     90.0              6.59   \n",
            "\n",
            "   player_pos       web_name  \n",
            "0           2          White  \n",
            "1           3       Trossard  \n",
            "2           3     Martinelli  \n",
            "3           2        Gabriel  \n",
            "4           3          Salah  \n",
            "5           3  Brereton Díaz  \n",
            "6           1           Neto  \n",
            "7           3          Foden  \n",
            "8           1          Muric  \n",
            "9           3          Bowen  \n",
            "     id_player  id_rival  player_team_id  is_home  minutes  fpl_total_points  \\\n",
            "6           77       7.0             3.0      0.0     90.0              7.79   \n",
            "8          172      16.0             6.0      1.0     90.0              7.10   \n",
            "12         113       9.0             1.0      1.0     90.0              6.31   \n",
            "25          49       8.0             2.0      0.0     90.0              4.73   \n",
            "28         597       5.0            14.0      0.0     90.0              4.59   \n",
            "..         ...       ...             ...      ...      ...               ...   \n",
            "519        818       8.0             2.0      0.0     90.0              0.00   \n",
            "527        665      10.0            12.0      1.0     90.0              0.00   \n",
            "528        335      10.0            12.0      1.0     90.0              0.00   \n",
            "538        778       8.0             2.0      0.0     90.0              0.00   \n",
            "539        765       8.0             2.0      0.0     90.0              0.00   \n",
            "\n",
            "     player_pos  web_name  \n",
            "6             1      Neto  \n",
            "8             1     Muric  \n",
            "12            1      Raya  \n",
            "25            1  Martinez  \n",
            "28            1     Onana  \n",
            "..          ...       ...  \n",
            "519           1     Gauci  \n",
            "527           1      Krul  \n",
            "528           1      Shea  \n",
            "538           1    Wright  \n",
            "539           1   Proctor  \n",
            "\n",
            "[71 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kXy09NvX1hzg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}